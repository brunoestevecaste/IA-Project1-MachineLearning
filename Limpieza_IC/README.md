#  Predicci贸n de Enfermedad Card铆aca: Limpieza de Datos y Feature Engineering

Hemos implementado un pipeline completo para evaluar y seleccionar la mejor estrategia de limpieza de datos e ingenier铆a de caracter铆sticas. Para ello hemos seguido los siguientes pasos:

- **Gesti贸n de valores faltantes y at铆picos**: Tratamiento diferenciado para valores codificados como `-9` y `?`.
- **Ingenier铆a de Caracter铆sticas**: Creaci贸n de nuevas variables sint茅ticas para capturar patrones de riesgo.
- **Codificaci贸n**: 
    - *Label encoder* para caracter铆sticas categ贸ricas con sentido ordinal.
    - *One-hot encoder* para caracter铆sticas categ贸ricas con sentido nominal.
- **Estandarizaci贸n**: Escalado de caracter铆sticas mediante Z-Score `StandardScaler`.
- **Modelado y Validaci贸n**:
    - Comparaci贸n de estrategias utilizando Regresi贸n Log铆stica como modelo base.
    - Validaci贸n cruzada estratificada `Stratified K-Fold` con 5 particiones.
    - Optimizaci贸n de hiperpar谩metros mediante Grid Search.
- **Evaluaci贸n**: Estimaci贸n del rendimiento y estabilidad del modelo.
$$
\text{Media de la precisi贸n} \pm \text{Desviaci贸n est谩ndar}
$$

- **Producci贸n**: Generaci贸n autom谩tica del archivo `submission.csv` utilizando la mejor configuraci贸n encontrada.
- **Visualizaciones**: Gr谩ficas de la distribuci贸n de los nulos, an谩lisis del bias/varianza y an谩lisis de la importancia de las caracter铆sticas.

### Resumen de Resultados

<div align="center">

| Estrategia de Imputaci贸n `-9` | Estrategia de Imputaci贸n `?` | CV Accuracy (Train) | CV Accuracy (Test) |
| :--- | :--- | :---: | :---: |
| Mediana y Moda | Mediana y Moda | 0.5451 卤 0.026 | **0.59782** |
| Mediana y Moda | MICE | 0.5505 卤 0.014 | 0.57065 |

</div>

## Gesti贸n de valores faltantes y at铆picos

Se identific贸 que el dataset conten铆a dos tipos distintos de codificaci贸n para representar la ausencia de informaci贸n: valores num茅ricos `-9` y caracteres de texto `?`. El an谩lisis separado de ambos patrones revela problemas estructurales en ciertas variables clave:

- Codificaci贸n `-9`: Como se observa en el primer gr谩fico, esta codificaci贸n afecta severamente a tres variables que superan el umbral cr铆tico del 20% de datos faltantes:

    - `ca`: Es la variable m谩s comprometida, con un 47.6% de sus registros marcados como `-9`.

    - `thal`: Presenta un 37.3% de datos ausentes bajo esta codificaci贸n.

    - `slope`: Supera ligeramente el umbral con un 23.9%.

    - Variables como `chol` y `fbs` tienen una afectaci贸n m铆nima con menos del 3%.

- Codificaci贸n `?`: El segundo gr谩fico muestra que est谩 m谩s extendido entre las variables (afecta a 9 caracter铆sticas), aunque con menor intensidad en la mayor铆a de ellas:

    - Nuevamente, `ca` con un 34.0% y `thal` con 23.1% son las 煤nicas que superan la l铆nea de corte del 20%.

    - Otras variables como `slope` con 13.0%, `fbs`, `oldpeak`, entre otras, presentan faltantes pero se mantienen en rangos m谩s manejables, entre 6% y 13%.

Existe una p茅rdida de informaci贸n sistem谩tica en las variables ca (n煤mero de vasos mayores) y thal (thalassemia). Al combinar ambas fuentes de error, estas columnas tienen m谩s de la mitad de sus datos comprometidos.

![-9](./images/menos_9.png)
![?](./images/interrogantes.png)

### Estrategias para los valores `-9`

- **Imputaci贸n simple**: Reemplazo por mediana (num茅ricas) y moda (categ贸ricas).

- **Categorizar**: Tratar los `-9` como una categor铆a nueva, -1 (num茅ricas) ya que todos los valores eran positivos, y 'Otros' (categ贸ricas). Pensamos que esto podr铆a ayudar al modelo a identificar patrones que relacionaran la ausencia de valores en esas determinadas pruebas.

- **Valores sanos**: Reemplazarlos por valores t铆picos en personas sanas. Pensamos que esto podr铆a funcionar ya que vimos que las filas con muchos `-9` estaban relacionadas con la etiqueta 0, es decir con personas sin enfermedad card铆aca.

- **Imputaci贸n avanzada**: KNN Imputer (vecinos m谩s cercanos) y IterativeImputer (imputaci贸n iterativa). 

### Qu茅 funcion贸 mejor

A pesar de que m茅todos avanzados como **KNN** y **MICE** mostraron m茅tricas ligeramente superiores en la validaci贸n cruzada interna, la imputaci贸n simple **(Mediana/Moda)** demostr贸 una capacidad de generalizaci贸n superior en el conjunto de test externo (Kaggle). Esto sugiere que los m茅todos complejos incurrieron en **sobreajuste** *(overfitting)*, generando relaciones artificiales que no se sosten铆an con datos nuevos. Esto se presenta especialmente en MICE, cuyo proceso iterativo forzar relaciones inexistentes en datasets peque帽os.

Por otro lado, la imputaci贸n por **'Valores Sanos'** super贸 a la estrategia de crear una nueva categor铆a num茅rica. Dado que la Regresi贸n Log铆stica es un modelo lineal, asume una relaci贸n ordinal en las variables; introducir un valor arbitrario como -1 rompe esta linealidad y puede llevar al modelo a interpretarlo err贸neamente como un valor extremo o negativo, en lugar de una ausencia de dato.

En conclusi贸n, la estrategia m谩s robusta fue la imputaci贸n por tendencia central combinada con la eliminaci贸n de las variables `ca` y `thal`, dado que su tasa de valores nulos (>50%) introduc铆a m谩s incertidumbre que informaci贸n.

### Estrategias para los valores `?`

- **Imputaci贸n simple**: Reemplazo por mediana (num茅ricas) y moda (categ贸ricas).

- **Imputaci贸n avanzada**: KNN Imputer (vecinos m谩s cercanos) y IterativeImputer (imputaci贸n iterativa). 

### Qu茅 funcion贸 mejor

De la misma forma que anteriomente, la imputaci贸n simple result贸 ganadora. La mediana y la moda, al ser est谩ticas, resultaron m谩s robustas, a pesar de que en validaci贸n cruzada se deduc铆a que la imputaci贸n avanzada funcionaba mejor.

## Ingenier铆a de Caracter铆sticas

### `combined_risk`(Peso: -0.4175)
Suma +1 por cada factor de riesgo presente: Edad > 55, sexo masculino, colesterol > 240, presi贸n arterial > 140 y angina inducida por ejercicio. Es la **variable m谩s importante del modelo**. Al agrupar m煤ltiples se帽ales d茅biles en una sola puntuaci贸n fuerte, permiti贸 al algoritmo identificar perfiles de alto riesgo con gran precisi贸n. Su peso negativo indica que a mayor puntuaci贸n, mayor probabilidad de enfermedad.

### `chest_pain_severity`(Peso: +0.0.2322)
Una transformaci贸n lineal del tipo de dolor de pecho para darle un sentido de severidad ordinal. 

### `age_chol_interaction`(Peso: +0.0.1870)
Interacci贸n entre la edad y el colesterol. Captura el riesgo biol贸gico real: tener el colesterol alto es m谩s peligroso cuanto mayor es el paciente. Esta variable tuvo mucho m谩s peso que la edad por s铆 sola, demostrando que el contexto importa m谩s que el dato aislado. 

### `hr_achievement`(Peso: +0.1045)
Es el porcentaje de la frecuencia card铆aca m谩xima te贸rica que el paciente logr贸 alcanzar. Un valor bajo sugiere incapacidad para alcanzar el esfuerzo m谩ximo esperado.

### `bp_risk`(Peso: +0.0686)
Desviaci贸n de la presi贸n arterial ideal. Distancia absoluta de la presi贸n del paciente respecto a 120 mmHg. Ayuda a identificar tanto hipertensi贸n como hipotensi贸n severa como factores de riesgo, algo que la variable lineal original no captura bien. 

### `oldpeak_adjusted`(Peso: -0.1695)
Depresi贸n del ST ajustada por edad. Aunque 煤til, tuvo menos peso que la variable original.

### `chol_risk`(Peso: ~0.0000)
Bandera binaria de colesterol alto. Al simplificar un dato continuo a un simple S铆/No, se perdi贸 informaci贸n valiosa. El modelo descart贸 esta variable en favor de `chol`y `age_chol_interaction`.

### Pesos que no cuadran con nuestra intuici贸n:
- `bp_risk`(Peso: +0.0686): A mayor desviaci贸n m谩s probabilidad de no tener enfermedad. Podr铆a estar relacionando la hipotensi贸n con enfermedad card铆aca o simplemente est谩 compensando la linealidad de la variable `combined_risk`.
- `chol`(Peso: +0.2280) y `age_chol_interaction`(Peso: +0.0.1870): Alto colesterol se relaciona con no tener enfermedad. Pesamos que puede deberse a que las personas enfermas toman medicaci贸n, lo que les baja colesterol. De esa forma, el colesterol alto se relaciona de forma natural con personas que no toman nada y que est谩n sanas. O puede deberse a la linealidad con la variable `combined_risk`.
- `cp_2.0`(Peso: +0.2600), `cp_2.0`(Peso: -0.2500) y `chest_pain_severity`(Peso: +0.0.2322): Angina t铆pica se relaciona con no tener enfermedad y dolor asintom谩tico se relaciona con s铆 tener enfermedad.



### Resumen 

<div align="center">

| Estado | Variable | Descripci贸n / Detalle |
| :--- | :--- | :--- |
| **Original** | `age` | Edad del paciente |
| **Original** | `sex` | Sexo (0: mujer, 1: hombre) |
| **Original** | `trestbps` | Presi贸n arterial en reposo |
| **Original** | `chol` | Colesterol s茅rico |
| **Original** | `fbs` | Glucosa en ayunas >120 mg/dl |
| **Original** | `restecg` | Resultado del ECG en reposo |
| **Original** | `thalach` | Frecuencia cardiaca m谩xima alcanzada |
| **Original** | `exang` | Angina inducida por ejercicio |
| **Original** | `oldpeak` | Depresi贸n del ST |
| **Original** | `slope` | Pendiente del ST (ordinal) |
| **Original** | `cp` | Tipo de dolor de pecho (1, 2, 3, 4) |
| **Eliminada** | `ca` | *Motivo:* >50% valores ausentes |
| **Eliminada** | `thal` | *Motivo:* >50% valores ausentes |
| **Nueva** | `combined_risk` | Suma de factores de riesgo (edad, sexo, colest., presi贸n, exang) |
| **Nueva** | `chest_pain_severity` | Conversi贸n ordinal del tipo de dolor de pecho |
| **Nueva** | `age_chol_interaction`| Interacci贸n entre edad y colesterol |
| **Nueva** | `hr_achievement` | % de frecuencia cardiaca m谩xima te贸rica alcanzada |
| **Nueva** | `bp_risk` | Distancia respecto a la presi贸n ideal |
| **Nueva** | `oldpeak_age_adj` | Ajuste de oldpeak seg煤n edad |
| **Nueva** | `chol_risk` | Indicador binario de colesterol >240 |
| **OHE** | `cp_{1.0-4.0}` | Variables *dummy* derivadas del tipo de dolor de pecho |
| **OHE** | `restecg_{0.0-2.0}` | Variables *dummy* derivadas del resultado ECG |

</div>

![Feature Importance](./images/feature_importance.png)

## Codificaci贸n

El uso de la Regresi贸n Log铆stica requer铆a entradas num茅ricas. La estrategia de codificaci贸n dependi贸 de la naturaleza de cada variable categ贸rica.

- **Label Encoder**: Se aplic贸 a variables binarias y ordinales. Una de sus ventajas es que mantiene la dimensionalidad baja, y adem谩s en este caso nos ayud贸 a preservar el orden inherente en variables donde "mayor" significa algo distinto o peor.

- **One-Hot Enconder**: Se aplic贸 en variables nominales como `cp`y `restecg`. El tipo de dolor de pecho 1 no es "menor" que el tipo 4; son cualitativamente distintos. De esta forma evitamos que el modelo asuma orden matem谩tico falso que sesgar铆a las predicciones. 

## Estandarizaci贸n

Se aplic贸 `StandardScaler` a todas las caracter铆sticas de entrada antes del entrenamiento. De esta forma, transformamos los datos para que tengan una media de 0 y una desviaci贸n est谩ndar de 1. La Regresi贸n Log铆stica utiliza optimizadores basados en gradientes (como `lbfgs`). Sin estandarizaci贸n, variables con magnitudes grandes (como `chol` ~250) dominar铆an a variables peque帽as (como `oldpeak` ~2.5), haciendo que el modelo ignore estas 煤ltimas. La estandarizaci贸n pone a todas las variables en igualdad de condiciones.

## Modelado y Validaci贸n

El proceso de evaluaci贸n fue dise帽ado para ser honesto y evitar el optimismo excesivo.

- **Regresi贸n Log铆stica**: Se eligi贸 como baseline por su interpretabilidad y robustez ante datasets peque帽os.

- **Stratified K-Fold (5 particiones)**:

Divide los datos en 5 partes asegurando que cada parte tenga la misma proporci贸n de enfermos/sanos que el total. Esto es vital para evitar que un fold de validaci贸n contenga solo casos "f谩ciles" o solo casos de una clase, lo que dar铆a una accuracy enga帽osa.

- **Grid Search**:

Automatizamos la b煤squeda de los mejores hiperpar谩metros (`C`, `penalty`, `solver`).

Nos permiti贸 descubrir que una regularizaci贸n moderada (`C` peque帽a) funcionaba mejor, confirmando que el dataset tiene mucho ruido y penalizar coeficientes altos ayuda a generalizar.

- **M茅trica Final (Media 卤 Std)**: Una desviaci贸n est谩ndar baja nos indic贸 que, aunque la accuracy no fuera estelar, el modelo era estable y confiable, no una casualidad estad铆stica.

## Conclusiones

![Curva de Aprendizaje](./images/learning_curve.png)

Observamos que el modelo sufre principalmente de **alto bias (subajuste)**. La curva de entrenamiento comienza alta pero desciende r谩pidamente hasta estancarse en una precisi贸n aproximada de 0.59. Esto indica que el modelo tiene dificultades para aprender los patrones subyacentes, incluso sobre los datos que ya ha visto.

Aunque te贸ricamente un modelo m谩s complejo deber铆a elevar la curva de entrenamiento, nuestros experimentos (como veremos posteriormente) muestran que aumentar la complejidad (o relajar la regularizaci贸n) no logra romper este 'techo de rendimiento'. Esto sugiere que estamos ante un caso de **error irreducible** o limitaci贸n en los datos: probablemente las variables actuales carecen de la se帽al suficiente para predecir mejor, especialmente tras haber eliminado caracter铆sticas potentes como `ca` y `thal`.

Por otro lado, observamos una **baja varianza**. La brecha entre entrenamiento y validaci贸n se cierra hacia el final, lo que indica que el modelo no est谩 memorizando (sobreajustando) los datos. Generaliza de forma consistente: su rendimiento en validaci贸n es casi id茅ntico al de entrenamiento.

Dado que las curvas convergen pero en un nivel bajo (planas), a帽adir m谩s registros (filas) probablemente no mejorar铆a el modelo. El problema no es la cantidad de pacientes, sino la calidad de la informaci贸n (features). La v铆a principal de mejora no es usar modelos m谩s complejos, sino recuperar variables predictivas eliminadas o encontrar nuevas caracter铆sticas que aporten informaci贸n real.